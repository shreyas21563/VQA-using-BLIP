\section{Dataset Description}
\label{sec:formatting}

%------------------------------------------------------------------------
We have utilized three distinct datasets to evaluate the performance of the BLIP model: VQA v2.0 Training, VQA v2.0 Validation, and the DAQUAR Dataset. Refer to Table 1 for further details.

\begin{table}[h]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Dataset & \#Images & \#Questions & \#Answers\\
\midrule
\href{https://visualqa.org/download.html}{VQA v2.0 Training} & 82783 & 443757 & 4437570\\
\href{https://visualqa.org/download.html}{VQA v2.0 Validation} & 40504 & 214354 & 2143540\\
\href{https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge}{DAQUAR} & 1449 & 5674 & 5674\\
\bottomrule
\end{tabular}
\caption{Comparison of \#Image, \#Question, and \#Answer Across Datasets}
\label{tab:example}
\end{table}

For the VQA v2.0 Training and Validation datasets, we were provided with 10 answers for each question. The majority is considered as the final ground truth answer. 

%-------------------------------------------------------------------------
